{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be prepping the data for a recommendation system. We will be making a content based recommendation system and for that we need to use NLP on the details section of the data. Towards the end of this notebook we also take a look at using NLP on the category section and using that to make content based recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ish/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ish/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# downloading resources and importing libraries\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data_for_notebooks/recomm_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "job_title         0\n",
       "company_name      0\n",
       "job_loc           0\n",
       "details           1\n",
       "category          0\n",
       "compensation      0\n",
       "start             0\n",
       "end             215\n",
       "skills            0\n",
       "href              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the data once\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_loc</th>\n",
       "      <th>details</th>\n",
       "      <th>category</th>\n",
       "      <th>compensation</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>skills</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>103</td>\n",
       "      <td>business development</td>\n",
       "      <td>promon</td>\n",
       "      <td>new delhi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>marketing professional</td>\n",
       "      <td>paid</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>business skills</td>\n",
       "      <td>http://letsintern.com/internship/Marketing-Pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id             job_title company_name    job_loc details  \\\n",
       "99  103  business development       promon  new delhi     NaN   \n",
       "\n",
       "                  category compensation       start  end  \\\n",
       "99  marketing professional         paid  2016-08-16  NaN   \n",
       "\n",
       "                      skills  \\\n",
       "99           business skills   \n",
       "\n",
       "                                                 href  \n",
       "99  http://letsintern.com/internship/Marketing-Pro...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check this out once \n",
    "df[df.details.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop the entry as it is only one entry \n",
    "df.dropna(subset = ['details'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape once again\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_loc</th>\n",
       "      <th>details</th>\n",
       "      <th>category</th>\n",
       "      <th>compensation</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>skills</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hr executive - recruitment</td>\n",
       "      <td>engenia technologies</td>\n",
       "      <td>gurgaon</td>\n",
       "      <td>we are seeking a hr recruiter who will...</td>\n",
       "      <td>human resources recruiter</td>\n",
       "      <td>paid</td>\n",
       "      <td>2019-03-02</td>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>hr practices</td>\n",
       "      <td>http://letsintern.com/internship/Human-Resourc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>telecalling &amp; lead generation</td>\n",
       "      <td>abalone technologies pvt ltd</td>\n",
       "      <td>noida</td>\n",
       "      <td>selected intern's day-to-day responsib...</td>\n",
       "      <td>tele sales executive</td>\n",
       "      <td>paid</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>office administration</td>\n",
       "      <td>http://letsintern.com/internship/Tele-Sales-Ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>digital marketing internship</td>\n",
       "      <td>brandstory digital marketing company</td>\n",
       "      <td>bangalore</td>\n",
       "      <td>are you looking for digital marketing ...</td>\n",
       "      <td>marketing professional</td>\n",
       "      <td>paid</td>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>digital marketing</td>\n",
       "      <td>http://letsintern.com/internship/Marketing-Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>recruitment of corporate bank back office post</td>\n",
       "      <td>bandhan pvt.ltd</td>\n",
       "      <td>kathua,barasat,bardhaman,bongoan,habra</td>\n",
       "      <td>huge opportunity in corporate bank for...</td>\n",
       "      <td>accountant</td>\n",
       "      <td>paid</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>analytical skills</td>\n",
       "      <td>http://letsintern.com/internship/Accountant-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>software developer</td>\n",
       "      <td>trippyigloo</td>\n",
       "      <td>bangalore</td>\n",
       "      <td>we are looking for interns who are wil...</td>\n",
       "      <td>software developer : python</td>\n",
       "      <td>paid</td>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>go(golang),java,mongodb,nginx,python</td>\n",
       "      <td>http://letsintern.com/internship/Software-Deve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       job_title  \\\n",
       "0   1                      hr executive - recruitment   \n",
       "1   2                   telecalling & lead generation   \n",
       "2   3                    digital marketing internship   \n",
       "3   4  recruitment of corporate bank back office post   \n",
       "4   5                              software developer   \n",
       "\n",
       "                           company_name  \\\n",
       "0                  engenia technologies   \n",
       "1          abalone technologies pvt ltd   \n",
       "2  brandstory digital marketing company   \n",
       "3                       bandhan pvt.ltd   \n",
       "4                           trippyigloo   \n",
       "\n",
       "                                  job_loc  \\\n",
       "0                                 gurgaon   \n",
       "1                                   noida   \n",
       "2                               bangalore   \n",
       "3  kathua,barasat,bardhaman,bongoan,habra   \n",
       "4                               bangalore   \n",
       "\n",
       "                                             details  \\\n",
       "0          we are seeking a hr recruiter who will...   \n",
       "1          selected intern's day-to-day responsib...   \n",
       "2          are you looking for digital marketing ...   \n",
       "3          huge opportunity in corporate bank for...   \n",
       "4          we are looking for interns who are wil...   \n",
       "\n",
       "                      category compensation       start         end  \\\n",
       "0    human resources recruiter         paid  2019-03-02  2019-08-28   \n",
       "1         tele sales executive         paid  2019-02-17  2019-08-30   \n",
       "2       marketing professional         paid  2018-12-25  2020-04-29   \n",
       "3                   accountant         paid  2019-03-12         NaN   \n",
       "4  software developer : python         paid  2019-01-30  2019-06-20   \n",
       "\n",
       "                                          skills  \\\n",
       "0                                   hr practices   \n",
       "1                          office administration   \n",
       "2                              digital marketing   \n",
       "3                              analytical skills   \n",
       "4           go(golang),java,mongodb,nginx,python   \n",
       "\n",
       "                                                href  \n",
       "0  http://letsintern.com/internship/Human-Resourc...  \n",
       "1  http://letsintern.com/internship/Tele-Sales-Ex...  \n",
       "2  http://letsintern.com/internship/Marketing-Pro...  \n",
       "3  http://letsintern.com/internship/Accountant-in...  \n",
       "4  http://letsintern.com/internship/Software-Deve...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to use the following features for creating filters in the app:\n",
    "\n",
    "1. Skills/Category\n",
    "2. Locations\n",
    "3. Compensation\n",
    "\n",
    "In the final app, the user will be choosing from the options provided or inputting the data themselves for these categories. Haven't decided on that part yet. Based on the profile ID they have entered, we will be using a content based recommendation system to recommend the user similar profiles. This similarity will be based on the details column.\n",
    "\n",
    "We will be creating functions to implement the following steps in this notebook : \n",
    "1. Normalize : Remove extra signs and numbers form the sentences (everything is already lowercase)\n",
    "2. Tokenize\n",
    "3. Remove extra space from all tokens\n",
    "4. Stem each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences):\n",
    "    '''\n",
    "    tokenizes a bunch of sentences after normalizing them and returns stemmed tokens.\n",
    "    \n",
    "    INPUT:\n",
    "    sentences - a paragraph that need to be tokenized\n",
    "    \n",
    "    OUTPUT:\n",
    "    tokens - list of stemmed tokens\n",
    "    \n",
    "    '''\n",
    "    # normalizing, tokenizing, lemmatizing \n",
    "    sentences = re.sub('\\W',' ',sentences) \n",
    "    sentences = re.sub('[0-9]',' ',sentences)\n",
    "\n",
    "    tokens = word_tokenize(sentences)\n",
    "    tokens = [i.strip() for i in tokens]\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(i) for i in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(df):\n",
    "    '''\n",
    "    returns a similarity matrix, in the form of a dataframe, between different internships by using the \n",
    "    details section of df.\n",
    "    \n",
    "    INPUT:\n",
    "    df - dataframe with 'details' as one of the columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    sim - similarity matrix(dataframe) with internship id as column and row labels \n",
    "    \n",
    "    '''\n",
    "    details = df['details']\n",
    "    vect = CountVectorizer(tokenizer= tokenize, stop_words = 'english')\n",
    "    tfidf = TfidfTransformer()\n",
    "    \n",
    "    mat = tfidf.fit_transform(vect.fit_transform(details).toarray()).toarray()\n",
    "    sim = np.dot(mat, mat.T)\n",
    "    sim = pd.DataFrame(sim, columns=df.id, index = df.id)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = similarity_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 624)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.to_csv('../data_for_notebooks/recommendation_matrix.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying out the recommendations in the make_recs notebook, I have come back to this notebook to make some changes. I think that we can maybe make better recommendations and thus we will try a few things out with this data(since it isn't big at all).\n",
    "\n",
    "The few ways that I can think of right now to change how recommendations are made:\n",
    "1. Do not use Tfidf and but stem tokens\n",
    "2. Lemmatize the words instead of stemming them\n",
    "3. Use lemmatization and do not use tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Do not use Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix_wo_tfidf(df):\n",
    "    '''\n",
    "    returns a similarity matrix, in the form of a dataframe, between different internships by using the \n",
    "    details section\n",
    "    \n",
    "    INPUT:\n",
    "    df - dataframe with 'details' as one of the columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    sim - similarity matrix(dataframe) with internship id as column and row labels \n",
    "    \n",
    "    '''\n",
    "    details = df['details']\n",
    "    vect = CountVectorizer(tokenizer= tokenize, stop_words = 'english')\n",
    "    \n",
    "    mat = vect.fit_transform(details).toarray()\n",
    "    sim = np.dot(mat, mat.T)\n",
    "    sim = pd.DataFrame(sim, columns=df.id, index = df.id)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_1 = similarity_matrix_wo_tfidf(df)\n",
    "sim_1.to_csv('../data_for_notebooks/recommendation_matrix_wo_tfidf.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Lemmatize the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lem(sentences):\n",
    "    '''\n",
    "    tokenizes a bunch of sentences after normalizing it and returns lemmatized tokens.\n",
    "    \n",
    "    INPUT:\n",
    "    sentences - a paragraph that needs to be tokenized\n",
    "    \n",
    "    OUTPUT:\n",
    "    tokens - list of lemmatized tokens\n",
    "    \n",
    "    '''\n",
    "    # normalizing, tokenizing, lemmatizing \n",
    "    sentences = re.sub('\\W',' ',sentences) \n",
    "    sentences = re.sub('[0-9]',' ',sentences)\n",
    "\n",
    "    tokens = word_tokenize(sentences)\n",
    "    tokens = [i.strip() for i in tokens]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(i) for i in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix_w_lem(df):\n",
    "    '''\n",
    "    returns a similarity matrix, in the form of a dataframe, between different internships by using the \n",
    "    details section\n",
    "    \n",
    "    INPUT:\n",
    "    df - dataframe with 'details' as one of the columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    sim - similarity matrix(dataframe) with internship id as column and row labels \n",
    "    \n",
    "    '''\n",
    "    details = df['details']\n",
    "    vect = CountVectorizer(tokenizer= tokenize_lem, stop_words = 'english')\n",
    "    tfidf = TfidfTransformer()\n",
    "    \n",
    "    mat = tfidf.fit_transform(vect.fit_transform(details).toarray()).toarray()\n",
    "    sim = np.dot(mat, mat.T)\n",
    "    sim = pd.DataFrame(sim, columns=df.id, index = df.id)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_2 = similarity_matrix_w_lem(df)\n",
    "sim_2.to_csv('../data_for_notebooks/recommendation_matrix_w_lem.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use lemmatization and do not use tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix_w_lem_wo_tfidf(df):\n",
    "    '''\n",
    "    returns a similarity matrix, in the form of a dataframe, between different internships by using the \n",
    "    details section\n",
    "    \n",
    "    INPUT:\n",
    "    df - dataframe with 'details' as one of the columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    sim - similarity matrix(dataframe) with internship id as column and row labels \n",
    "    '''\n",
    "    details = df['details']\n",
    "    vect = CountVectorizer(tokenizer= tokenize_lem, stop_words = 'english')\n",
    "    tfidf = TfidfTransformer()\n",
    "    \n",
    "    mat = vect.fit_transform(details).toarray()\n",
    "    sim = np.dot(mat, mat.T)\n",
    "    sim = pd.DataFrame(sim, columns=df.id, index = df.id)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_3 = similarity_matrix_w_lem_wo_tfidf(df)\n",
    "sim_3.to_csv('../data_for_notebooks/recommendation_matrix_w_lem_wo_tfidf.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After forming these 3 with the details section, we try an alternate approach and try to use the 'category' column to form the similarity matrix. This should give us more relevant results as there are a high no. of common categories and similar internships have really similar category names. Thus, in the make_recs notebook, we will try using this too and compare it with the results of the above 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix_cat(df):\n",
    "    '''\n",
    "    returns a similarity matrix, in the form of a dataframe, between different internships by using the \n",
    "    cat section\n",
    "    \n",
    "    INPUT:\n",
    "    df - dataframe with 'category' as one of the columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    sim - similarity matrix(dataframe) with internship id as column and row labels \n",
    "    '''\n",
    "    cats = df['category']\n",
    "    vect = CountVectorizer(tokenizer= tokenize, stop_words = 'english')\n",
    "    tfidf = TfidfTransformer()\n",
    "    \n",
    "    mat = vect.fit_transform(cats).toarray()\n",
    "    sim = np.dot(mat, mat.T)\n",
    "    sim = pd.DataFrame(sim, columns=df.id, index = df.id)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: The above has been formed in a similar way to sim_1, i.e, without tfidf and with stemming the tokens.This is because when we actually compare the recommendations given using different similarity matrices, we see that sim_1 gives us the best results. Thus later, what we do is that we combine both of sim_1 and sim_cat to get relevant and interesting recommendations. If sim_cat had been made using tdidf then the value of its elements would have been really small compared to sim_1's and it would have been a little difficult trying to make a similarity matrix which uses both of these to make recommendations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_cat = similarity_matrix_cat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_cat.to_csv('../data_for_notebooks/recommendation_df_cat.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
